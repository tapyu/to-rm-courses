function train(ğ—, ğƒ, ğ”š, Ï†, Ï†Ê¼)
    L = length(ğ”š) # number of layers
    for (ğ±â‚â‚™â‚, ğâ‚â‚™â‚) âˆˆ zip(eachcol(ğ—), eachcol(ğƒ)) # n-th instance
        ğ²â‚â‚™â‚ = rand(L)  # output of the l-th layer at the instant n
        ğ²Ê¼â‚â‚™â‚ = rand(L) # diff of the output of the l-th layer at the instant n
        ğ›…â‚â‚™â‚ = rand(L) # all local gradients of all layers
        # forward phase
        for (l, ğ–â½Ë¡â¾â‚â‚™â‚) âˆˆ ğ”š # l-th layer
            ğ¯â½Ë¡â¾â‚â‚™â‚ = l==1 ? ğ–â½Ë¡â¾â‚â‚™â‚*ğ±â‚â‚™â‚ : ğ–â½Ë¡â¾â‚â‚™â‚*ğ²â‚â‚™â‚[l-1] # induced local field
            ğ²â‚â‚™â‚[l] = map(Ï†, ğ¯â½Ë¡â¾â‚â‚™â‚)
            ğ²Ê¼â‚â‚™â‚[l] = map(Ï†Ê¼, ğ²â‚â‚™â‚[l])
        end
        # backward phase
        for l âˆˆ L:-1:1 # hidden layers
            ğ›…â‚â‚™â‚[l] = l==L ? ğ²Ê¼â‚â‚™â‚[L] .* (ğâ‚â‚™â‚ - ğ²â‚â‚™â‚[L]) : ğ²Ê¼â‚â‚™â‚[l] .* ğ”š[l+1]*ğ›…â‚â‚™â‚[l+1] # vector of local gradients of the l-th layer
            ğ”š[l] = l==1 ? ğ”š[l]+Î·*ğ›…â‚â‚™â‚[l]*ğ±â‚â‚™â‚' : ğ”š[l]+Î·*ğ›…â‚â‚™â‚[l]*ğ²â‚â‚™â‚[l-1]' # learning equation
        end
    end
    return ğ”š
end