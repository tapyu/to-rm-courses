using Random

function grid_search_cross_validation(ğ—, ğƒ, K, hyperparameters)
    # ğ— â¡ the dataset without the test instances [attributes X instances]
    # K â¡ number of folds
    # hyperparameters â¡ vector of vector of all hyperparameters

    ğ— = ğ—[shuffle(1:end), :] # shuffle dataset
    ğ— = [fill(-1, size(ğ—,2))'; ğ—] # add the -1 input (bias)

    ğ“§ = reshape(ğ—, size(ğ—,1), K, :) # split the dataset into K folds

    e_best = Inf # mean accuracy of the best set of hyperparameters (begin as Inf)
    best_set_of_hyperparameter = Any
    for set_of_hyperparameter âˆˆ Iterators.product(hyperparameters...)
        mâ‚ = set_of_hyperparameter[1] # number of neurons of the hidden layer (hyperparameter)
        mâ‚‚ = size(ğƒ, 1) # number of neurons on the output layer = number of outputs
        Ï† = set_of_hyperparameter[2] # activation function

        ğ = rand(K) # the accuracy for each fold
        for k âˆˆ 1:K

            ğ”š = Dict(1 => rand(mâ‚, size(ğ—,1)), 2 => rand(mâ‚‚, mâ‚+1)) # 1 => first layer (hidden layer) 2 => second layer (output layer)
            ğ—â‚œáµ£â‚™ = ğ“§[:,:,1:end.!=k] # train dataset
            ğ—â‚œáµ£â‚™ = reshape(ğ—â‚œáµ£â‚™, size(ğ—â‚œáµ£â‚™, 1), :)

            ğ—áµ¥â‚â‚— = ğ“§[:,:,k] # validation dataset

            for _ âˆˆ 1:Nâ‚‘
                ğ—â‚œáµ£â‚™ = ğ—â‚œáµ£â‚™[shuffle(1:end), :] # shuffle dataset
                ğ”š = train(ğ—â‚œáµ£â‚™, ğ”š, Ï†)
            end
            ğ[k] = test(ğ—áµ¥â‚â‚—, ğ”š, Ï†)
        end

        e_set = sum(ğ)/length(ğ) # mean accuracy for this set of hyperparameters

        if e_set < e_best
            global e_best = e_set
            global best_set_of_hyperparameter = set_of_hyperparameter
        end

    end

    return best_set_of_hyperparameter
    
end