using FileIO, JLD2, Random, LinearAlgebra, Plots
Î£=sum

## load the data
ğ—, labels = FileIO.load("Dataset/Iris [uci]/iris.jld2", "ğ—", "ğ") # ğ— â¡ [attributes X instances]
# PS choose only one!!!
# uncomment â†“ if you want to train for all attributes
# ğ— = [fill(-1, size(ğ—,2))'; ğ—] # add the -1 input (bias)
# uncomment â†“ if you want to train for petal length and width (to plot the decision surface)
ğ— = [fill(-1, size(ğ—,2))'; ğ—[3:4,:]] # add the -1 input (bias)

## useful functions
function shuffle_dataset(ğ—, ğ)
    shuffle_indices = Random.shuffle(1:size(ğ—,2))
    return ğ—[:, shuffle_indices], ğ[shuffle_indices]
end

function train(ğ—â‚œáµ£â‚™, ğâ‚œáµ£â‚™, ğ°)
    ğâ‚œáµ£â‚™ = rand(length(ğâ‚œáµ£â‚™)) # vector of errors
    Ï† = uâ‚™ -> uâ‚™â‰¥0 ? 1 : 0 # activation function of the simple Perceptron
    for (n, (ğ±â‚™, dâ‚™)) âˆˆ enumerate(zip(eachcol(ğ—â‚œáµ£â‚™), ğâ‚œáµ£â‚™))
        Î¼â‚™ = dot(ğ±â‚™,ğ°) # inner product
        yâ‚™ = Ï†(Î¼â‚™) # for the training phase, you do not pass yâ‚™ to a harder decisor (the McCulloch and Pitts's activation function) since you are in intended to classify yâ‚™. Rather, you are interested in updating ğ°
        eâ‚™ = dâ‚™ - yâ‚™
        ğ° += Î±*eâ‚™*ğ±â‚™
        ğâ‚œáµ£â‚™[n] = eâ‚™
    end
    Ïµâ‚œáµ£â‚™ = sum(ğâ‚œáµ£â‚™)/length(ğâ‚œáµ£â‚™) # the accuracy for this epoch
    return ğ°, Ïµâ‚œáµ£â‚™
end

function test(ğ—â‚œâ‚›â‚œ, ğâ‚œâ‚›â‚œ, ğ°)
    Ï† = uâ‚™ -> uâ‚™>0 ? 1 : 0 # activation function of the simple Perceptron
    ğâ‚œâ‚›â‚œ = rand(length(ğâ‚œâ‚›â‚œ)) # vector of errors
    for (n, (ğ±â‚™, dâ‚™)) âˆˆ enumerate(zip(eachcol(ğ—â‚œâ‚›â‚œ), ğâ‚œâ‚›â‚œ))
        Î¼â‚™ = ğ±â‚™â‹…ğ° # inner product
        yâ‚™ = Ï†(Î¼â‚™) # for the simple Perceptron, yâ‚™ âˆˆ {0,1}. Therefore, it is not necessary to pass yâ‚™ to a harder decisor since Ï†(â‹…) already does this job
        ğâ‚œâ‚›â‚œ[n] = dâ‚™ - yâ‚™
    end
    Ïµâ‚œâ‚›â‚œ = sum(ğâ‚œâ‚›â‚œ)/length(ğâ‚œâ‚›â‚œ) # the accuracy for this realization
    return Ïµâ‚œâ‚›â‚œ
end

## algorithm hyperparameters
Náµ£ = 20 # number of realizations
Nâ‚ = size(ğ—, 1) # =5 (including bias) number of Attributes, that is, input vector size at each intance. They mean: sepal length, sepal width, petal length, petal width
N = size(ğ—, 2) # =150 number of instances(samples)
Nâ‚œáµ£â‚™ = 80 # % percentage of instances for the train dataset
Nâ‚œâ‚›â‚œ = 20 # % percentage of instances for the test dataset
Nâ‚‘ = 100 # number of epochs
Î± = 0.01 # learning step

## init
all_ğ›œÌ„â‚œâ‚›â‚œ, all_ÏƒÂ²â‚‘, all_ğ°â‚’â‚šâ‚œ = rand(3), rand(3), rand(Nâ‚,3)
for (i, desired_set) âˆˆ enumerate(("setosa", "virginica", "versicolor"))
    local ğ = labels.==desired_set # dâ‚™ âˆˆ {0,1}
    ğ›œâ‚œâ‚›â‚œ = rand(Náµ£) # vector that stores the error test dataset for each realization (to compute the final statistics)
    for náµ£ âˆˆ 1:Náµ£ # for each realization
        ğ›œâ‚œáµ£â‚™ = rand(Nâ‚‘) # vector that stores the error train dataset for each epoch (to see its evolution)
        global ğ° = ones(Nâ‚) # initialize a new McCulloch-Pitts neuron (a new set of parameters)
        global ğ— # ?

        ğ—, ğ = shuffle_dataset(ğ—, ğ)
        # hould-out
        ğ—â‚œáµ£â‚™ = ğ—[:,1:(N*Nâ‚œáµ£â‚™)Ã·100]
        ğâ‚œáµ£â‚™ = ğ[1:(N*Nâ‚œáµ£â‚™)Ã·100]
        global ğ—â‚œâ‚›â‚œ = ğ—[:,length(ğâ‚œáµ£â‚™)+1:end]
        global ğâ‚œâ‚›â‚œ = ğ[length(ğâ‚œáµ£â‚™)+1:end]
        for nâ‚‘ âˆˆ 1:Nâ‚‘ # for each epoch
            ğ°, ğ›œâ‚œáµ£â‚™[nâ‚‘] = train(ğ—â‚œáµ£â‚™, ğâ‚œáµ£â‚™, ğ°)
            ğ—â‚œáµ£â‚™, ğâ‚œáµ£â‚™ = shuffle_dataset(ğ—â‚œáµ£â‚™, ğâ‚œáµ£â‚™)
        end
        ğ›œâ‚œâ‚›â‚œ[náµ£] = test(ğ—â‚œâ‚›â‚œ, ğâ‚œâ‚›â‚œ, ğ°)
        if náµ£ == 1
            all_ğ°â‚’â‚šâ‚œ[:,i] = ğ° # save the optimum value reached during the 1th realization for setosa, versicolor, and virginica
            local p = plot(ğ›œâ‚œáµ£â‚™)
            display(p)
        end
    end
    ğ›œÌ„â‚œâ‚›â‚œ = sum(ğ›œâ‚œâ‚›â‚œ)/length(ğ›œâ‚œâ‚›â‚œ) # mean of the accuracy of all realizations
    ğ”¼ğ›œÂ² = Î£(ğ›œâ‚œâ‚›â‚œ.^2)/length(ğ›œâ‚œâ‚›â‚œ) # second moment of all realization accuracies
    ÏƒÂ²â‚‘ = ğ”¼ğ›œÂ² - ğ›œÌ„â‚œâ‚›â‚œ^2 # variance of all realization accuracies
    
    # save the performance
    all_ğ›œÌ„â‚œâ‚›â‚œ[i] = ğ›œÌ„â‚œâ‚›â‚œ
    all_ÏƒÂ²â‚‘[i] = ÏƒÂ²â‚‘

end

## plot setosa set decision surface
ğ = labels.=="setosa" # dâ‚™ âˆˆ {0,1}
ğ—, labels = FileIO.load("Dataset/Iris [uci]/iris.jld2", "ğ—", "ğ") # ğ— â¡ [attributes X instances]
ğ—_setosa = ğ—[:, ğ.==1]
ğ—_not_setosa = ğ—[:, ğ.!=1]

# surface decision
ğ°â‚’â‚šâ‚œâ½Ë¢â¾ = all_ğ°â‚’â‚šâ‚œ[:, 1] # optimum weights for the setosa dataset (only for the third and fourth attributes, that is, for petal length and petal width)
if length(ğ°â‚’â‚šâ‚œâ½Ë¢â¾) == 3 # plot the surface only if the learning procedure was taken with only two attributes, the petal length and petal width (equals to 3 because the bias)
    Ï† = uâ‚™ -> uâ‚™â‰¥0 ? 1 : 0 # activation function of the simple Perceptron
    xâ‚ƒ_range = floor(minimum(ğ—[3,:])):.1:ceil(maximum(ğ—[3,:]))
    xâ‚„_range = floor(minimum(ğ—[4,:])):.1:ceil(maximum(ğ—[4,:]))
    y(xâ‚ƒ, xâ‚„) = Ï†(dot([-1, xâ‚ƒ, xâ‚„], ğ°â‚’â‚šâ‚œâ½Ë¢â¾))
    p = surface(xâ‚ƒ_range, xâ‚„_range, y, camera=(60,40,0), xlabel = "petal length", ylabel = "petal width", zlabel="decision surface")


    # scatter plot for the petal length and petal length width for the setosa class
    scatter!(ğ—_setosa[3,:], ğ—_setosa[4,:], ones(length(ğ—_setosa[4,:])),
            markershape = :hexagon,
            markersize = 4,
            markeralpha = 0.6,
            markercolor = :green,
            markerstrokewidth = 3,
            markerstrokealpha = 0.2,
            markerstrokecolor = :black,
            xlabel = "petal length",
            ylabel = "petal width",
            camera = (60,40,0),
            label = "setosa set")

    scatter!(ğ—_not_setosa[3,:], ğ—_not_setosa[4,:], zeros(length(ğ—_not_setosa[4,:])),
            markershape = :hexagon,
            markersize = 4,
            markeralpha = 0.6,
            markercolor = :red,
            markerstrokewidth = 3,
            markerstrokealpha = 0.2,
            markerstrokecolor = :black,
            xlabel = "petal length",
            ylabel = "petal width",
            label = "not setosa set")
            
    display(p)
end