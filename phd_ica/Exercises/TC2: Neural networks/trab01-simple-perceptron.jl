using FileIO, JLD2, Random, LinearAlgebra, Plots, LaTeXStrings
Œ£=sum

## load the data
ùêó, labels = FileIO.load("Dataset/Iris [uci]/iris.jld2", "ùêó", "ùêù") # ùêó ‚û° [attributes X instances]
# PS choose only one!!!
# uncomment ‚Üì if you want to train for all attributes
ùêó = [fill(-1, size(ùêó,2))'; ùêó] # add the -1 input (bias)
# uncomment ‚Üì if you want to train for petal length and width (to plot the decision surface)
# ùêó = [fill(-1, size(ùêó,2))'; ùêó[3:4,:]] # add the -1 input (bias)

## useful functions
function shuffle_dataset(ùêó, ùêù)
    shuffle_indices = Random.shuffle(1:size(ùêó,2))
    return ùêó[:, shuffle_indices], ùêù[shuffle_indices]
end

function train(ùêó‚Çú·µ£‚Çô, ùêù‚Çú·µ£‚Çô, ùê∞)
    ùêû‚Çú·µ£‚Çô = rand(length(ùêù‚Çú·µ£‚Çô)) # vector of errors
    œÜ = u‚Çô -> u‚Çô‚â•0 ? 1 : 0 # McCulloch and Pitts's activation function (step function)
    for (n, (ùê±‚Çô, d‚Çô)) ‚àà enumerate(zip(eachcol(ùêó‚Çú·µ£‚Çô), ùêù‚Çú·µ£‚Çô))
        Œº‚Çô = dot(ùê±‚Çô,ùê∞) # inner product
        y‚Çô = œÜ(Œº‚Çô) # for the training phase, you do not pass y‚Çô to a harder decisor (the McCulloch and Pitts's activation function) since you are in intended to classify y‚Çô. Rather, you are interested in updating ùê∞ (??? TODO)
        e‚Çô = d‚Çô - y‚Çô
        ùê∞ += Œ±*e‚Çô*ùê±‚Çô
        ùêû‚Çú·µ£‚Çô[n] = e‚Çô
    end
    œµ‚Çú·µ£‚Çô = sum(ùêû‚Çú·µ£‚Çô)/length(ùêû‚Çú·µ£‚Çô) # the accuracy for this epoch
    return ùê∞, œµ‚Çú·µ£‚Çô
end

function test(ùêó‚Çú‚Çõ‚Çú, ùêù‚Çú‚Çõ‚Çú, ùê∞, is_confusion_matrix=false)
    œÜ = u‚Çô -> u‚Çô>0 ? 1 : 0 # McCulloch and Pitts's activation function (step function)
    ùêû‚Çú‚Çõ‚Çú = rand(length(ùêù‚Çú‚Çõ‚Çú)) # vector of errors
    for (n, (ùê±‚Çô, d‚Çô)) ‚àà enumerate(zip(eachcol(ùêó‚Çú‚Çõ‚Çú), ùêù‚Çú‚Çõ‚Çú))
        Œº‚Çô = ùê±‚Çô‚ãÖùê∞ # inner product
        y‚Çô = œÜ(Œº‚Çô) # for the simple Perceptron, y‚Çô ‚àà {0,1}. Therefore, it is not necessary to pass y‚Çô to a harder decisor since œÜ(‚ãÖ) already does this job
        ùêû‚Çú‚Çõ‚Çú[n] = d‚Çô - y‚Çô
    end
    if !is_confusion_matrix # return the accuracy for this realization
        œµ‚Çú‚Çõ‚Çú = sum(ùêû‚Çú‚Çõ‚Çú)/length(ùêû‚Çú‚Çõ‚Çú)
        return œµ‚Çú‚Çõ‚Çú
    else
        return Int.(ùêû‚Çú‚Çõ‚Çú) # return the errors over the instances to plot the confusion matrix
    end
end

## algorithm hyperparameters
N·µ£ = 20 # number of realizations
N‚Çê = size(ùêó, 1) # =5 (including bias) number of Attributes, that is, input vector size at each intance. They mean: sepal length, sepal width, petal length, petal width
N = size(ùêó, 2) # =150 number of instances(samples)
N‚Çú·µ£‚Çô = 80 # % percentage of instances for the train dataset
N‚Çú‚Çõ‚Çú = 20 # % percentage of instances for the test dataset
N‚Çë = 100 # number of epochs
Œ± = 0.01 # learning step

## init
all_ùõúÃÑ‚Çú‚Çõ‚Çú, all_œÉ¬≤‚Çë, all_ùê∞‚Çí‚Çö‚Çú = rand(3), rand(3), rand(N‚Çê,3)
for (i, desired_label) ‚àà enumerate(("setosa", "virginica", "versicolor"))
    local ùêù = labels.==desired_label # d‚Çô ‚àà {0,1}
    ùõú‚Çú‚Çõ‚Çú = rand(N·µ£) # vector that stores the error test dataset for each realization (to compute the final statistics)
    for n·µ£ ‚àà 1:N·µ£ # for each realization
        # initializing!
        ùõú‚Çú·µ£‚Çô = rand(N‚Çë) # vector that stores the error train dataset for each epoch (to see its evolution)
        global ùê∞ = ones(N‚Çê) # initialize a new McCulloch-Pitts neuron (a new set of parameters)
        global ùêó # ?

        # prepare the data!
        ùêó, ùêù = shuffle_dataset(ùêó, ùêù)
        # hould-out
        global ùêó‚Çú·µ£‚Çô = ùêó[:,1:(N*N‚Çú·µ£‚Çô)√∑100]
        global ùêù‚Çú·µ£‚Çô = ùêù[1:(N*N‚Çú·µ£‚Çô)√∑100]
        global ùêó‚Çú‚Çõ‚Çú = ùêó[:,length(ùêù‚Çú·µ£‚Çô)+1:end]
        global ùêù‚Çú‚Çõ‚Çú = ùêù[length(ùêù‚Çú·µ£‚Çô)+1:end]

        # train and test!
        for n‚Çë ‚àà 1:N‚Çë # for each epoch
            ùê∞, ùõú‚Çú·µ£‚Çô[n‚Çë] = train(ùêó‚Çú·µ£‚Çô, ùêù‚Çú·µ£‚Çô, ùê∞)
            ùêó‚Çú·µ£‚Çô, ùêù‚Çú·µ£‚Çô = shuffle_dataset(ùêó‚Çú·µ£‚Çô, ùêù‚Çú·µ£‚Çô)
        end
        ùõú‚Çú‚Çõ‚Çú[n·µ£] = test(ùêó‚Çú‚Çõ‚Çú, ùêù‚Çú‚Çõ‚Çú, ùê∞)
        
        # make plots!
        if n·µ£ == 1
            all_ùê∞‚Çí‚Çö‚Çú[:,i] = ùê∞ # save the optimum value reached during the 1th realization for setosa, versicolor, and virginica
            # if all attributes was taken into account, compute the accuracyxepochs for all classes
            if length(ùê∞) != 3
                local p = plot(ùõú‚Çú·µ£‚Çô, label="", xlabel=L"Epochs", ylabel=L"\epsilon_n", linewidth=2, title="Training accuracy for $(desired_label) class by epochs")
                display(p)
                savefig(p, "figs/trab1 (simple perceptron)/epsilon_n-by-epochs-for$(desired_label).png")
                # for the setosa class, compute the confusion matrix
                if desired_label == "setosa"
                    ùêÇ = zeros(2,2) # confusion matrix
                    ùêû‚Çú‚Çõ‚Çú = test(ùêó‚Çú‚Çõ‚Çú, ùêù‚Çú‚Çõ‚Çú, ùê∞, true)
                    for n ‚àà 1:length(ùêû‚Çú‚Çõ‚Çú)
                        # predicted x true label
                        ùêÇ[ùêù‚Çú‚Çõ‚Çú[n]-ùêû‚Çú‚Çõ‚Çú[n]+1, ùêù‚Çú‚Çõ‚Çú[n]+1] += 1
                    end
                    h = heatmap(ùêÇ, xlabel="Predicted labels", ylabel="True labels", xticks=(1:2, ("setosa", "not setosa")), yticks=(1:2, ("setosa", "not setosa")), title="Confusion matrix for the setosa class")
                    savefig(h, "figs/trab1 (simple perceptron)/setosa-heatmap.png")
                    display(h) # TODO: put the number onto each heatmap square
                end
            end
            # decision surface
            if length(ùê∞) == 3 # plot the surface only if the learning procedure was taken with only two attributes, the petal length and petal width (equals to 3 because the bias)
                œÜ = u‚Çô -> u‚Çô‚â•0 ? 1 : 0 # activation function of the simple Perceptron
                x‚ÇÉ_range = floor(minimum(ùêó[2,:])):.1:ceil(maximum(ùêó[2,:]))
                x‚ÇÑ_range = floor(minimum(ùêó[3,:])):.1:ceil(maximum(ùêó[3,:]))
                y(x‚ÇÉ, x‚ÇÑ) = œÜ(dot([-1, x‚ÇÉ, x‚ÇÑ], ùê∞))
                p = surface(x‚ÇÉ_range, x‚ÇÑ_range, y, camera=(60,40,0), xlabel = "petal length", ylabel = "petal width", zlabel="decision surface")


                # scatter plot for the petal length and petal length width for the setosa class
                # train and desired label 
                scatter!(ùêó‚Çú·µ£‚Çô[2,ùêù‚Çú·µ£‚Çô.==1], ùêó‚Çú·µ£‚Çô[3,ùêù‚Çú·µ£‚Çô.==1], ones(length(filter(x->x==1, ùêù‚Çú·µ£‚Çô))),
                        markershape = :hexagon,
                        markersize = 4,
                        markeralpha = 0.6,
                        markercolor = :green,
                        markerstrokewidth = 3,
                        markerstrokealpha = 0.2,
                        markerstrokecolor = :black,
                        xlabel = "petal\nlength",
                        ylabel = "petal width",
                        camera = (60,40,0),
                        label = "$(desired_label) train set")
                
                # test and desired label 
                scatter!(ùêó‚Çú‚Çõ‚Çú[2,ùêù‚Çú‚Çõ‚Çú.==1], ùêó‚Çú‚Çõ‚Çú[3,ùêù‚Çú‚Çõ‚Çú.==1], ones(length(filter(x->x==1, ùêù‚Çú‚Çõ‚Çú))),
                        markershape = :cross,
                        markersize = 4,
                        markeralpha = 0.6,
                        markercolor = :green,
                        markerstrokewidth = 3,
                        markerstrokealpha = 0.2,
                        markerstrokecolor = :black,
                        xlabel = "petal\nlength",
                        ylabel = "petal width",
                        camera = (60,40,0),
                        label = "$(desired_label) test set")

                # train and not desired label 
                scatter!(ùêó‚Çú·µ£‚Çô[2,ùêù‚Çú·µ£‚Çô.==0], ùêó‚Çú·µ£‚Çô[3,ùêù‚Çú·µ£‚Çô.==0], zeros(length(filter(x->x==0, ùêù‚Çú·µ£‚Çô))),
                        markershape = :hexagon,
                        markersize = 4,
                        markeralpha = 0.6,
                        markercolor = :red,
                        markerstrokewidth = 3,
                        markerstrokealpha = 0.2,
                        markerstrokecolor = :black,
                        xlabel = "petal\nlength",
                        ylabel = "petal width",
                        camera = (60,40,0),
                        label = "not $(desired_label) train set")

                # test and not desired label 
                scatter!(ùêó‚Çú‚Çõ‚Çú[2,ùêù‚Çú‚Çõ‚Çú.==0], ùêó‚Çú‚Çõ‚Çú[3,ùêù‚Çú‚Çõ‚Çú.==0], zeros(length(filter(x->x==0, ùêù‚Çú‚Çõ‚Çú))),
                        markershape = :cross,
                        markersize = 4,
                        markeralpha = 0.6,
                        markercolor = :red,
                        markerstrokewidth = 3,
                        markerstrokealpha = 0.2,
                        markerstrokecolor = :black,
                        xlabel = "petal\nlength",
                        ylabel = "petal width",
                        camera = (60,40,0),
                        label = "not $(desired_label) test set")
                
                title!("Decision surface for the class $(desired_label)")
                display(p)
                savefig(p,"figs/trab1 (simple perceptron)/decision-surface-for-$(desired_label).png")
            end
        end
    end
    ùõúÃÑ‚Çú‚Çõ‚Çú = sum(ùõú‚Çú‚Çõ‚Çú)/length(ùõú‚Çú‚Çõ‚Çú) # mean of the accuracy of all realizations
    ùîºùõú¬≤ = Œ£(ùõú‚Çú‚Çõ‚Çú.^2)/length(ùõú‚Çú‚Çõ‚Çú) # MSE (Mean squared erro), that is, the second moment of realization accuracies
    œÉ¬≤‚Çë = ùîºùõú¬≤ - ùõúÃÑ‚Çú‚Çõ‚Çú^2 # variance of all realization accuracies
    
    # save the performance
    all_ùõúÃÑ‚Çú‚Çõ‚Çú[i] = ùõúÃÑ‚Çú‚Çõ‚Çú
    all_œÉ¬≤‚Çë[i] = œÉ¬≤‚Çë
end


### dataset 02 - artificial dataset ###

## hyperparameters
œÉ‚Çì = .1 # signal standard deviation
N = 40 # number of instances
N‚Çê = 2 # number of attributes (not includes the bias)

## generate dummy data
ùêó‚ÇÅ = [œÉ‚Çì*randn(10)'; œÉ‚Çì*randn(10)']
ùêó‚ÇÇ = [œÉ‚Çì*randn(10)'.+1; œÉ‚Çì*randn(10)']
ùêó‚ÇÉ = [œÉ‚Çì*randn(10)'; œÉ‚Çì*randn(10)'.+1]
ùêó‚ÇÑ = [œÉ‚Çì*randn(10)'.+1; œÉ‚Çì*randn(10)'.+1]

ùêó = [fill(-1,N)'; [ùêó‚ÇÅ ùêó‚ÇÇ ùêó‚ÇÉ ùêó‚ÇÑ]]
ùêù = [zeros(30);ones(10)]

## init
MSE‚Çú‚Çõ‚Çú = rand(N·µ£)
figs_surface = Array{Plots.Plot{Plots.GRBackend},1}[]
figs_training_accuracy = Array{Plots.Plot{Plots.GRBackend},1}[]
for n·µ£ ‚àà 1:N·µ£
    # initialize
    global ùê∞ = randn(N‚Çê+1)
    MSE‚Çú·µ£‚Çô = zeros(N‚Çë) # vector that stores the error train dataset for each epoch (to see its evolution)

    # prepare the data!
    global  ùêó, ùêù
    ùêó, ùêù = shuffle_dataset(ùêó, ùêù)
    # hould-out
    global ùêó‚Çú·µ£‚Çô = ùêó[:,1:(N*N‚Çú·µ£‚Çô)√∑100]
    global ùêù‚Çú·µ£‚Çô = ùêù[1:(N*N‚Çú·µ£‚Çô)√∑100]
    global ùêó‚Çú‚Çõ‚Çú = ùêó[:,length(ùêù‚Çú·µ£‚Çô)+1:end]
    global ùêù‚Çú‚Çõ‚Çú = ùêù[length(ùêù‚Çú·µ£‚Çô)+1:end]

    # train!
    for n‚Çë ‚àà 1:N‚Çë
        ùê∞, MSE‚Çú·µ£‚Çô[n‚Çë] = train(ùêó‚Çú·µ£‚Çô, ùêù‚Çú·µ£‚Çô, ùê∞)
        ùêó‚Çú·µ£‚Çô, ùêù‚Çú·µ£‚Çô = shuffle_dataset(ùêó‚Çú·µ£‚Çô, ùêù‚Çú·µ£‚Çô)
    end
    # test!
    MSE‚Çú‚Çõ‚Çú[n·µ£] = test(ùêó‚Çú‚Çõ‚Çú, ùêù‚Çú‚Çõ‚Çú, ùê∞)

    # make plots!
    # MSE training x Epochs
    local fig = plot(MSE‚Çú·µ£‚Çô, label="", xlabel=L"Epochs", ylabel=L"MSE", linewidth=2, title="Training accuracy by epochs")
    push!(figs_training_accuracy, [fig])

    # decision surface
    œÜ = u‚Çô -> u‚Çô‚â•0 ? 1 : 0 # activation function of the simple Perceptron
    x‚ÇÅ_range = floor(minimum(ùêó[2,:])):.1:ceil(maximum(ùêó[2,:]))
    x‚ÇÇ_range = floor(minimum(ùêó[3,:])):.1:ceil(maximum(ùêó[3,:]))
    y(x‚ÇÅ, x‚ÇÇ) = œÜ(dot([-1, x‚ÇÅ, x‚ÇÇ], ùê∞))
    fig = surface(x‚ÇÅ_range, x‚ÇÇ_range, y, camera=(60,40,0), xlabel = L"x_1", ylabel = L"x_2", zlabel="decision surface")
    push!(figs_surface, [fig])

    # train and desired label 
    scatter!(ùêó‚Çú·µ£‚Çô[2,ùêù‚Çú·µ£‚Çô.==1], ùêó‚Çú·µ£‚Çô[3,ùêù‚Çú·µ£‚Çô.==1], ones(length(filter(x->x==1, ùêù‚Çú·µ£‚Çô))), markershape = :hexagon, markersize = 4, markeralpha = 0.6, markercolor = :green, markerstrokewidth = 3, markerstrokealpha = 0.2, markerstrokecolor = :black, label = "desired class train set")
    
    # test and desired label 
    scatter!(ùêó‚Çú‚Çõ‚Çú[2,ùêù‚Çú‚Çõ‚Çú.==1], ùêó‚Çú‚Çõ‚Çú[3,ùêù‚Çú‚Çõ‚Çú.==1], ones(length(filter(x->x==1, ùêù‚Çú‚Çõ‚Çú))), markershape = :cross, markersize = 4, markeralpha = 0.6, markercolor = :green, markerstrokewidth = 3, markerstrokealpha = 0.2, markerstrokecolor = :black, label = "desired class test set")

    # train and not desired label 
    scatter!(ùêó‚Çú·µ£‚Çô[2,ùêù‚Çú·µ£‚Çô.==0], ùêó‚Çú·µ£‚Çô[3,ùêù‚Çú·µ£‚Çô.==0], zeros(length(filter(x->x==0, ùêù‚Çú·µ£‚Çô))), markershape = :hexagon, markersize = 4, markeralpha = 0.6, markercolor = :red, markerstrokewidth = 3, markerstrokealpha = 0.2, markerstrokecolor = :black, label = "not desired class train set")

    # test and not desired label 
    scatter!(ùêó‚Çú‚Çõ‚Çú[2,ùêù‚Çú‚Çõ‚Çú.==0], ùêó‚Çú‚Çõ‚Çú[3,ùêù‚Çú‚Çõ‚Çú.==0], zeros(length(filter(x->x==0, ùêù‚Çú‚Çõ‚Çú))), markershape = :cross, markersize = 4, markeralpha = 0.6, markercolor = :red, markerstrokewidth = 3, markerstrokealpha = 0.2, markerstrokecolor = :black, label = "not desired class test set")
    title!("Decision surface for the desired class")
end

accuracy = sum(MSE‚Çú‚Çõ‚Çú)/N·µ£
# find closest surface
i = 1
MSE‚Çú‚Çõ‚Çú_closest_to_accuracy = MSE‚Çú‚Çõ‚Çú[1]
for n·µ£ ‚àà 2:N·µ£
    if MSE‚Çú‚Çõ‚Çú[n·µ£] < MSE‚Çú‚Çõ‚Çú_closest_to_accuracy
        global MSE‚Çú‚Çõ‚Çú_closest_to_accuracy = MSE‚Çú‚Çõ‚Çú[n·µ£]
        global i = n·µ£
    end
end

# plot training set MSE for the realization MSE test closest to accuracy
display(figs_training_accuracy[i][1])
savefig(figs_training_accuracy[i][1], "figs/trab1 (simple perceptron)/epsilon_n-by-epochs-dummy-data.png")
# plot surface decision for the realization MSE test closest to accuracy
display(figs_surface[i][1])
savefig(figs_training_accuracy[i][1], "figs/trab1 (simple perceptron)/decision-surface-for-dummy-data.png")